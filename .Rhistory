img <- readJPEG("RMSEcheck.jpg")
packages <- c("SticsOnR", "CroPlotR","SticsRFiles","Metrics","ggplot2","ggpubr","jpeg")
lapply(packages, library, character.only=TRUE)
img <- readJPEG("RMSEcheck.jpg")
test <- read.csv("C:/Users/PolsinelliM/OneDrive - AGR-AGR/Mesbahteam/STICS/PerfEval/PotatoAtl/stats_evalRU_ver8.4.csv")
val <- data.frame(Split=as.numeric(),Features=as.numeric(),ntree=as.numeric,
mtry=as.numeric(),train_mse=as.numeric(),test_mse=as.numeric())
val <- data.frame(Split=as.numeric(),Features=as.numeric(),num_tree=as.numeric,
var_nodes=as.numeric(),train_mse=as.numeric(),test_mse=as.numeric())
val <- data.frame(pplit=as.numeric(),Features=as.numeric(),num_tree=as.numeric,
var_nodes=as.numeric(),train_mse=as.numeric(),test_mse=as.numeric())
val <- data.frame(ttsplit=as.numeric(),Features=as.numeric(),num_tree=as.numeric,
var_nodes=as.numeric(),train_mse=as.numeric(),test_mse=as.numeric())
packages <- c("dplyr","readxl","randomForest","caret","Metrics","ggplot2","tidyr","reshape2","RColorBrewer")
lapply(packages, library, character.only=TRUE)
wd <- getwd()
mlalone <- paste(wd,"/MattRamsay_RU_20152021/mrData.csv",sep="")
#hybrid_data <- paste(wd,"",sep="")
dataname <- "MR"
run <- 1
hybrid <- F
tuning <- F
if (hybrid){
data <- data.frame(read.csv(hybrid_data))
dir <- paste(wd,"/",dataname,"_Hybridrun",run,sep="")
rf_res <- "hybrid_pred.csv" #file name for hybrid predictions
} else{
data <- data.frame(read.csv(mlalone))
dir <- paste(wd,"/",dataname,"_RFrun",run,sep="")
rf_res <- "RF_pred.csv" #file name for RF alone predictions
}
#select only datapoints that have %sand info (have soil samples)
ss_data <- subset(data, data$sh_PER_SAN != 0) %>% select(6:33,35,41:47,50:55,58,59,62:69,72:79,82:89,92:108)
# yld_dist_snd <- ggplot(ss_data, aes(x=yield_tha)) + geom_histogram(color="black", fill="white") + labs(x="Yield (t/ha)", title = "Distribution of Russet Yield Datapoints with Field Soil Information")
# yld_dist_snd
ss_data$PH1[which(ss_data$PH1 %in% c(0))] <- 6.0 #replace missing pH values with pH of 6 as per CANSIS data
#move field ID, year, and yield columns to front
ss_data <- ss_data %>% dplyr::select("plant_ye", everything())
ss_data <- ss_data %>% dplyr::select("CFIDYr", everything())
ss_data <- ss_data %>% dplyr::select("yield_tha", everything())
#functions----------------------------------------------------------------------
calc_metrics <- function(actual,predicted){
mse <- mse(actual, predicted)
rmse <- rmse(actual, predicted)
rrmse <- rmse/mean(actual)
r2 <- cor(actual,predicted)^2*100
bias <- bias(actual, predicted)
pbias <- bias/mean(actual)*100
return (c(mse,rmse,rrmse,r2,bias,pbias))
}
control <- trainControl(method='repeatedcv',
number=10,
repeats=3,
search='grid')
tunegrid <- expand.grid(.mtry = (1:60))
View(tunegrid)
View(tunegrid)
ind <- sample(2, nrow(ss_data), replace = TRUE, prob=c(0.8,0.2))
train_x <- ss_data[ind==1,4:c]
train_y <- ss_data[ind==1,1]
test_x <- ss_data[ind==2,4:c]
test_y <- ss_data[ind==2,1]
set.seed(1234)
all_train <- merge(train_x,train_y)
train_x <- ss_data[ind==1,4:c]
ind <- sample(2, nrow(ss_data), replace = TRUE, prob=c(0.8,0.2))
train_x <- ss_data[ind==1,4:c]
View(ss_data)
View(ss_data)
c <- length(ss_data)
ind <- sample(2, nrow(ss_data), replace = TRUE, prob=c(0.8,0.2))
train_x <- ss_data[ind==1,4:c]
train_y <- ss_data[ind==1,1]
test_x <- ss_data[ind==2,4:c]
test_y <- ss_data[ind==2,1]
all_train <- merge(train_x,train_y)
View(all_train)
View(all_train)
all_train <- ss_data[ind==1,1,4:c]
all_train <- train_x
all_train$yield <- train_y
View(all_train)
View(all_train)
train_x <- ss_data[ind==1]
train_x <- ss_data[ind==1,1:c]
View(train_x)
View(train_x)
train_x <- ss_data[ind==1,(1,4:c)]
train_x <- ss_data[ind==1,select(1,4:c)]
train_x <- ss_data[ind==1,1:c] %>% select(1,4:c)
View(all_train)
View(all_train)
View(train_x)
View(train_x)
tunegrid <- expand.grid(.mtry = (1:20))
rf_gridsearch <- train(yield_tha ~ .,
data = train_x,
method = 'rf',
metric = 'RMSE',
tuneGrid = tunegrid)
control <- trainControl(method='repeatedcv',
number=10,
repeats=3,
search='grid')
install.packages(ranger)
install.packages("ranger")
rf_gridsearch <- train(yield_tha ~ .,
data = train_x,
method = 'ranger',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid)
rf_gridsearch <- train(yield_tha ~ .,
data = train_x,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid)
View(rf_gridsearch)
View(rf_gridsearch)
rf_gridsearch
train <- ss_data[ind==1,1:c] %>% select(1,4:c)
test <- ss_data[ind==2,1:c] %>% select(1,4:c)
rf_pred <- predict(rf_gridsearch,test)
calc_metrics(test[1],rf_pred)
test[1]
rf_pred
typeof(rf_pred)
typeof(test[1])
as.list(rf_pred)
b <- as.list(rf_pred)
View(b)
View(b)
typeof(train_y)
train_y
b <- as.numeric(rf_pred)
calc_metrics(test[1],as.numeric(rf_pred))
calc_metrics(as.numeric(test[1]),as.numeric(rf_pred))
typeof(test[1])
y <- test[1]
View(y)
View(y)
as.numeric(y)
test_y <- ss_data[ind==2,1]
test_y <- ss_data[ind==2,1]
y <- ss_data[ind==2,1]
calc_metrics(y,as.numeric(rf_pred))
tunegrid <- expand.grid(.mtry = (1:60), .ntree=c(100:1000))
tunegrid <- expand.grid(.mtry = (1:60), .ntree=seq(100,1000,by=100))
View(tunegrid)
View(tunegrid)
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'ranger',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid)
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid)
tunegrid <- expand.grid(.mtry = (1:60))
for (nt in seq(100,1000,by=100)){
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
}
modellist <- list()
for (nt in seq(100,1000,by=100)){
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
key <- toString(nt)
modellist[[key]] <- rf_gridsearch
}
View(modellist)
View(modellist)
tunegrid <- expand.grid(.mtry = (1:3))
View(rf_gridsearch)
View(rf_gridsearch)
print(paste("best mtry:",rf_gridsearch$bestTune$mtry,
"train_RMSE:",rf_gridsearch$results$RMSE, "test_RMSE:", pred_res[2],sep=" "))
pred_res <- calc_metrics(y,as.numeric(rf_pred))
print(paste("best mtry:",rf_gridsearch$bestTune$mtry,
"train_RMSE:",rf_gridsearch$results$RMSE, "test_RMSE:", pred_res[2],sep=" "))
n <- as.numeric(rf_gridsearch$bestTune$mtry)
print(paste("Ntree: ",key,"\n",sep=""))
print(paste("Ntree: ",key,sep=""))
print(paste("best mtry:",n,
"train_RMSE:",rf_gridsearch$results$RMSE[rf_gridsearch$results$mtry==n],
"test_RMSE:", pred_res[2],sep=" "))
for (nt in seq(300,500)){
set.seed(1234)
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
key <- toString(nt)
modellist[[key]] <- rf_gridsearch
rf_pred <- predict(rf_gridsearch,test)
pred_res <- calc_metrics(y,as.numeric(rf_pred))
n <- as.numeric(rf_gridsearch$bestTune$mtry)
print(paste("Ntree: ",key,sep=""))
print(paste("best mtry:",n,
"train_RMSE:",rf_gridsearch$results$RMSE[rf_gridsearch$results$mtry==n],
"test_RMSE:", pred_res[2],sep=" "))
}
tunegrid <- expand.grid(.mtry = (1:3))
for (nt in seq(300,500)){
set.seed(1234)
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
key <- toString(nt)
modellist[[key]] <- rf_gridsearch
rf_pred <- predict(rf_gridsearch,test)
pred_res <- calc_metrics(y,as.numeric(rf_pred))
n <- as.numeric(rf_gridsearch$bestTune$mtry)
print(paste("Ntree: ",key,sep=""))
print(paste("best mtry:",n,
"train_RMSE:",rf_gridsearch$results$RMSE[rf_gridsearch$results$mtry==n],
"test_RMSE:", pred_res[2],sep=" "))
}
print("Training with 10-Fold Cross Validation")
for (nt in seq(300,500)){
set.seed(1234)
key <- toString(nt)
print(paste("Ntree: ",key,sep=""))
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
modellist[[key]] <- rf_gridsearch
rf_pred <- predict(rf_gridsearch,test)
pred_res <- calc_metrics(y,as.numeric(rf_pred))
n <- as.numeric(rf_gridsearch$bestTune$mtry)
print(paste("best mtry:",n,
"train_RMSE:",rf_gridsearch$results$RMSE[rf_gridsearch$results$mtry==n],
"test_RMSE:", pred_res[2],sep=" "))
}
rint("Training with 10-Fold Cross Validation")
for (nt in seq(300,500,by=100)){
set.seed(1234)
key <- toString(nt)
print(paste("Ntree: ",key,sep=""))
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
modellist[[key]] <- rf_gridsearch
rf_pred <- predict(rf_gridsearch,test)
pred_res <- calc_metrics(y,as.numeric(rf_pred))
n <- as.numeric(rf_gridsearch$bestTune$mtry)
print(paste("best mtry:",n,
"train_RMSE:",rf_gridsearch$results$RMSE[rf_gridsearch$results$mtry==n],
"test_RMSE:", pred_res[2],sep=" "))
}
x <- (1:60)
test_y[1:1]
test_y[1:2]
#Feature Selection--------------------------------------------------------------
featselec <- function(train_x,train_y,test_x,test_y, nt=500){
set.seed(1234)
varlist <- list()
#CV for feature selection
CV <- rfcv(
train_x,
train_y,
cv.fold = 5,
scale = "log",
step = 0.5,
mtry = function(p)
max(1, floor(sqrt(p))))
nvars <- as.data.frame(CV$error.cv)
nvars$vars <- as.numeric(rownames(nvars))
v <- nvars$vars[nvars$`CV$error.cv` == min(nvars$`CV$error.cv`)]
mtry <- as.data.frame(tuneRF(train_x, train_y, stepFactor = 1.5))
n <- mtry$mtry[mtry$OOBError == min(mtry$OOBError)]
rf <- randomForest(
train_x,
y = train_y,
proximity = TRUE,
ntree = nt,
mtry = n,
plot = TRUE)
print(rf)
#get variable importance
var_imp <- rf$importance
vars <- row.names(rf$importance)
importance <- data.frame(vars, var_imp) %>% arrange(desc(var_imp))
write.csv(importance, file = "variable_importance.csv", row.names = F)
j <- 1
while (j <= v + 5) { #use additional 5 features
trnx <- train_x[importance$vars[1:j]]
tstx <- test_x[importance$vars[1:j]]
mtry <- as.data.frame(tuneRF(train_x, train_y, stepFactor = 1.5))
n <- mtry$mtry[mtry$OOBError == min(mtry$OOBError)]
rf <-
randomForest(
trnx,
y = train_y,
proximity = TRUE,
ntree = 300,
mtry = n,
plot = TRUE
)
trnm <- calc_metrics(train_y, rf[3]$predicted)
pred <- predict(rf, tstx, type = "response", predict.all = TRUE)
tstm <- calc_metrics(test_y, pred[[1]])
#number of features, ntree, mtry, train mse, test mse
val <- data.frame(v, nt, n, trnm[1], testm[1])
varlist[[j]] <- val
print(paste("number of features:",v,"ntree:",nt,"mtry:",n,"train MSE:",
trn[1],"test MSE:",testm[1],sep=" "))
print(importance$vars[1:j])
j <- j + 1
}
return (varlist)
}
#Hyperparameter tuning (mtry and ntree)-----------------------------------------
hype_tune <- fuction(train, test, y, folds=10, repeats=3, mtry_seq=(1:60), ntree_seq=seq(100,900,by=200)){
#Hyperparameter tuning (mtry and ntree)-----------------------------------------
hype_tune <- fuction(train, test, y, folds=10, repeats=3, mtry_seq=(1:60),
ntree_seq=seq(100,900,by=200)){
hype_tune <- function(train, test, y, folds=10, repeats=3, mtry_seq=(1:60),
ntree_seq=seq(100,900,by=200)){
#train - all training data (including train y)
#test - test X values
#y - test y values
modellist <- list()
control <- trainControl(method='repeatedcv',
number=folds,
repeats=3,
search='grid')
tunegrid <- expand.grid(.mtry = mtry_seq)
print("Training with 10-Fold Cross Validation")
for (nt in ntree_seq){
set.seed(1234)
key <- toString(nt)
print(paste("Ntree: ",key,sep=""))
rf_gridsearch <- train(yield_tha ~ .,
data = train,
method = 'rf',
metric = 'RMSE',
trControl = control,
tuneGrid = tunegrid,
ntree=nt)
modellist[[key]] <- rf_gridsearch
rf_pred <- predict(rf_gridsearch,test)
pred_res <- calc_metrics(y,as.numeric(rf_pred))
n <- as.numeric(rf_gridsearch$bestTune$mtry)
print(paste("best mtry:",n,
"train_RMSE:",rf_gridsearch$results$RMSE[rf_gridsearch$results$mtry==n],
"test_RMSE:", pred_res[2],sep=" "))
}
return (modellist)
}
dir
View(modellist)
View(modellist)
View(rf_gridsearch)
View(rf_gridsearch)
if (!require("randomForest")){
install.packages("randomForest")
}
if (!require("caret")){
install.packages("caret")
}
if (!require("dplyr")){
install.packages("dplyr")
}
if (!require("Metrics")){
install.packages("Metrics")
}
if (!require("ggplot2")){
install.packages("ggplot2")
}
packages <- c("dplyr","readxl","randomForest","caret","Metrics","ggplot2","tidyr","reshape2","RColorBrewer")
lapply(packages, library, character.only=TRUE)
lapply(packages, library, character.only=TRUE)
wd <- getwd()
mlalone <- paste(wd,"/MattRamsay_RU_20152021/mrData.csv",sep="")
#hybrid_data <- paste(wd,"",sep="")
dataname <- "MR"
run <- 1
